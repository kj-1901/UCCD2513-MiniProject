{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c0347b2",
   "metadata": {},
   "source": [
    "# Learning Outcomes\n",
    "- Quantify the image segmentation performance: Intersection over Union (IOU).\n",
    "- Image gradients -> edge detection (image segmentation method)\n",
    "- Contour (curves joining the boundaries of object (homogenous regions))\n",
    "- Contour properties and features (area, perimeter, center of mass, bounding box).\n",
    "- Blob detection (if manage to cover)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f23175",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979a44bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6883bb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0648c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 7)\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from util_func import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0056a9b8",
   "metadata": {},
   "source": [
    "### IOU\n",
    "Formulas:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4469ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIOU(boxA, boxB):\n",
    "    \"\"\"Args:\n",
    "    It should be(x1, y1, x2, y2)\"\"\"\n",
    "    x_start = max(boxA[0], boxB[0])\n",
    "    y_start = max(boxA[1], boxB[1])\n",
    "    x_end = min(boxA[2], boxB[2])\n",
    "    y_end = min(boxA[3], boxB[3])\n",
    "    \n",
    "    interArea = max(0, x_end - x_start + 1) * max(0, y_end - y_start + 1)\n",
    "    \n",
    "    # area of A and area of B\n",
    "    areaA = (boxA[2] - boxA[1] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    areaB = (boxB[2] - boxB[1] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "    \n",
    "    return interArea / (areaA + areaB - interArea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a09ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"image/lena.jfif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbcaab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = cv.selectROIs(\"boxes\", img, showCrosshair = False)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.detroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f9bc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59b58a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conver_xywh_to_xyzy(box):\n",
    "    return [box[0], box[1], box[0] + box[2], box[1] + box[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afae33dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = convert_xywh_to_xyzy(boxes[0])\n",
    "pred = convert_xywh_to_xyzy(boxes[1])\n",
    "\n",
    "img_copy = img.copy()\n",
    "cv.rectangle(img_copy, (gt[0], gt[1]), (gt[2], gt[3]), (0, 0, 225), 1)\n",
    "cv.rectangle(img_copy, (pred[0], pred[1]), (pred[2], pred[3]), (255, 0, 20), 1)\n",
    "cv.putText(img_copy, f\"IOU: {computeIOU(gt, pred):.3f}\", (10, 25), \n",
    "           cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "show_img(\"IOU\", img_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a554df",
   "metadata": {},
   "source": [
    "### Image gradient / edge detecion\n",
    "One of the most operators: Sobel. At the backend, convolution with specific kernel:\n",
    "\n",
    "$$\\begin{matrix} -1 & 0 & 1 \\\\ -2 & 0 & 2 \\\\ -1 & 0 & 1 \\end{matrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8327be",
   "metadata": {},
   "source": [
    "### caveat (bit depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a4d12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"images/wood_planck.jfif\", 0)\n",
    "\n",
    "th = cv.threshold(img, 200, 255, cv.THRES_BINARY_INV)[1]\n",
    "\n",
    "show_img(\"binary\", th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921eedf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sobelx_8u = cv.Sobel(th, cv.CV_8U, 1, 0)\n",
    "\n",
    "# correct way\n",
    "sobelx_32f = cv.Sobel(th, cv.CV_32F, 1, 0)\n",
    "sobelx = cv.convertScaleAbs(sobelx_32f)\n",
    "\n",
    "plt.subplot(121), plt_img(sobelx_8u, \"CV_8U\")\n",
    "plt.subplot(122), plt_img(sobelx, \"CV_32F\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ae4566",
   "metadata": {},
   "source": [
    "### Contstruct gradient map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4434fad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"images/chessboard.png\", 0)\n",
    "\n",
    "# apply sobel x and sobel y\n",
    "sobelx = cv.Sobel(img, cv_32F, 1, 0)\n",
    "sobelx_8u= cv.convertScaleAbs(sobelx)\n",
    "sobely = cv.Sobel(img, cv_32F, 0, 1)\n",
    "sobely_8u = cv.convertScaleAbs(sobely)\n",
    "\n",
    "# gradient\n",
    "gradient = cv.magnitude(sobelx, sobely)\n",
    "# direction\n",
    "direction = np.arctan2(sobelx, sobely) * 180 / np.pi % 100\n",
    "\n",
    "plt.subplot(221), plt_img(sobelx_8u, \"vertical\")\n",
    "plt.subplot(222), plt_img(sobely_8u, \"horinzontal\")\n",
    "plt.subplot(223), plt_img(gradiet, cmap = \"jet\"), plt.title(\"gradient\"), plt.colorbar()\n",
    "plt.subplot(224), plt_img(direction, cmap = \"jet\"), plt.title(\"direction\"), plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795e85ff",
   "metadata": {},
   "source": [
    "### Canny edge detectors\n",
    "- Enhance accuracy by reducing false positives\n",
    "- Flexible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e30abd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"images/chair.jpg\", 0)\n",
    "\n",
    "edge = cv.Canny(img, 100, 300)\n",
    "\n",
    "plt.subplot(121), plt_img(img, \"grayscale\")\n",
    "plt.subplot(122), plt_img(edge, \"Canny\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a778565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"images/chair.jpg\", 0)\n",
    "\n",
    "edge = cv.Canny(img, 30, 150)\n",
    "\n",
    "plt.subplot(121), plt_img(img, \"grayscale\")\n",
    "plt.subplot(122), plt_img(edge, \"Canny\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f29b9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple example: adjust one parameter:threshold1\n",
    "img = cv.imread(\"images/bridge.jfif\")\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "ratio = 2.5\n",
    "ksize = 3\n",
    "wn = \"Canny\"\n",
    "trackbarName = \"Threshold\"\n",
    "\n",
    "def cannyThreshold(val):\n",
    "    \"\"\"val is Threshold\"\"\"\n",
    "    edge = cv.Canny(gray, val, val * ration, apertureSize = ksize)\n",
    "    # create mask\n",
    "    mask = edge != 0\n",
    "    res = img * (mask[:, :, None].astype(np.uint8))\n",
    "    cv.imshow(wn, res)\n",
    "    \n",
    "cv.namedWindow(wn)\n",
    "cv.createTrackbar(trackbarName, wn, 10, 100, cannyThreshold)\n",
    "\n",
    "cv.waitKe(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba079433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_canny(img, method, sigma = 0.33):\n",
    "    \"\"\"Args:\n",
    "    img: grayscale image\n",
    "    method: median, otsu, triangle\n",
    "    sigma: 0.33 (default)\"\"\"\n",
    "    if method == \"median\":\n",
    "        Th = np.median(img)\n",
    "    \n",
    "    elif method == \"triangle\":\n",
    "        Th = cv.thresholding(img, 0, 255, cv.THRES_TRIANGLE)[0]\n",
    "        \n",
    "    elif method == \"otsu\":\n",
    "        Th = cv.thresholding(img, 0, 255, cv.THRES_OTSU)[0]\n",
    "        \n",
    "    Thresh1 = (1 - sigma) * Th\n",
    "    Thresh2 = (1 + sugma) * Th\n",
    "    \n",
    "    return cv.Canny(img, Thresh1, Thresh2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89064a9d",
   "metadata": {},
   "source": [
    "### Contour detection\n",
    "1. Read an image\n",
    "2. Threshold / Edge detection\n",
    "3. The output from step 2 can be parse into `cv.findContour()`.\n",
    "4. (optional) draw contour, cv.drawContour()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe3e28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect = np.zeros((256, 256), dtype = np.uint8)\n",
    "\n",
    "cv.rectangle(rect, (25, 25), (231, 231), 255, -1)\n",
    "\n",
    "show_img(\"rectangle\", rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e515c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, _ = cv.findContour(rect, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "print(contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ec87f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656fe477",
   "metadata": {},
   "outputs": [],
   "source": [
    "contours[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1936a64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_bgr = cv.cvtColor(rect, cv.COLOR_GRAY2BGR)\n",
    "\n",
    "cv.drawContours(img_bgr contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "show_img(\"contours\", img_bgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2afc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"images/monitor.jfif\", 0)\n",
    "\n",
    "th = cv.thresholding(img, 200, 255, cv.THRESH_BINARY_INV)[1]\n",
    "\n",
    "#contour\n",
    "contours, _ = cv.findContour(th, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "img_bgr = cv.cvtColor(img, cv.COLOR_GRAY2BGR)\n",
    "cv.drawContours(img_bgr, contours, -1, (-, 255, 0), 2)\n",
    "\n",
    "show_img(\"contour\", img_bgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa2bc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6440dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, _ = cv.findContour(th, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "img_bgr = cv.cvtColor(img, cv.COLOR_GRAY2BGR)\n",
    "cv.drawContours(img_bgr, contours, -1, (-, 255, 0), 2)\n",
    "\n",
    "show_img(\"contour\", img_bgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a63c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple way to sift through contours\n",
    "contours, _ = cv.findContour(th, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#select the contour that has the highest number of points\n",
    "length = [len(c) for c in contours]\n",
    "cnt = contours[np.argmax(length)]\n",
    "\n",
    "img_bgr = cv.cvtColor(img, cv.COLOR_GRAY2BGR)\n",
    "cv.drawContours(img_bgr, [cnt], -1, (-, 255, 0), 2)\n",
    "\n",
    "show_img(\"contour\", img_bgr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e03767d",
   "metadata": {},
   "source": [
    "### Contour features\n",
    "- area\n",
    "- perimeter\n",
    "- centroid\n",
    "- bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ee691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = cv.moments(cnt)\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f67829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# centroid\n",
    "cx = int(M['m10'] / M['m00'])\n",
    "cy = int(M['m01'] / M['m00'])\n",
    "print(f\"The centroid of monitor conour: {(cx, cy)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4801693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# area and perimeter\n",
    "area = cv.contourArea(cnt)\n",
    "peri = cv.arcLength(cnt, True)\n",
    "\n",
    "print(f\"area of monitor contour: {area}\")\n",
    "print(f\"perimeter of monitor contour: {peri:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f9f958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply edge detection and contour properties to segment\n",
    "img = cv.imread(\"images/remote-controller.webp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84891cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42a371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize ->grayscale -> bilateral filter -> edge (canny) -> area -> DP approximation\n",
    "factor = 300 / im.shape[1]\n",
    "img = cv.resize(img, None, fx = factor, fy = factor)\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "blur = cv.bilateralFilter(gray, 7, 19, 13)\n",
    "edge = auto_canny(blur, method = \"triangle\")\n",
    "\n",
    "show_img(\"edge\", edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42f9fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, _ = cv.findContours(edge, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#sort the contour with respect to contour area in descending order, and grab the first 5 largest contours\n",
    "contours = sorted(contours, key = cv.contourArea, reverse = True)[:5]\n",
    "\n",
    "for c in contours:\n",
    "    peri = cv.arcLength(c, True)\n",
    "    approx = cv.approxPolyDP(c, 0.1 * peri, True)\n",
    "    \n",
    "    if len(approx) == 4:\n",
    "        screen = c\n",
    "        break\n",
    "        \n",
    "img_copy = img.copy()\n",
    "cv.drawContours(img, [screen], -1, (0, 255, 2), 2)\n",
    "show_img(\"contour\", img_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f10371",
   "metadata": {},
   "source": [
    "### Additional Contour Properties\n",
    "$$circularity = \\frac{ 4 * pi * Area }{ perimeter ** 2 }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fc0048",
   "metadata": {},
   "source": [
    "### Demo on red color segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69738bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "redLow1 = (0, 90, 40)\n",
    "redHigh1 = (10, 255, 210)\n",
    "\n",
    "redLow2 = (170, 90, 40)\n",
    "redHigh2 = (179, 255, 210)\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    sys.exit(\"No webcam detected\")\n",
    "\n",
    "fixed_width = min_area = 500\n",
    "factor = fixed_width / cap.get(3)  # frame widhth\n",
    "kernel = np.ones((3, 3), dtype = np.uint8)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"No frame received\")\n",
    "        break\n",
    "        \n",
    "    # resize -> blurring -> change to hsv -> mask integration -> morphological operations ->\n",
    "    # find contours -> bounding box\n",
    "    resized = cv.resize(frame, None, fx = factor, fy = factor)\n",
    "    blur = cv.GaussianBlur(resized, (5, 5), 0)\n",
    "    img_hsv = cv.cvtColor(blur, COLOR_BGR2HSV)\n",
    "    \n",
    "    mask1 = cv.inRange(img_hsv, redLow1, redHigh1)\n",
    "    mask2 = cv.inRange(img_hsv, redLow2, redHigh2)\n",
    "    # Opening to remove noises\n",
    "    mask = cv.morphologyEx(mask, cv.MORPH_OPEN, kernel, iteration = 2)\n",
    "    \n",
    "    # contours\n",
    "    contours, _ = cv.findContours(mask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    bbs = []\n",
    "    \n",
    "    for c in contours:\n",
    "        area = cv.contourArea(c)\n",
    "        \n",
    "        if area > min_area:\n",
    "            bb = cv.boundinRect(c)\n",
    "            bbs.append(bb)\n",
    "            M = cv.moments(c)\n",
    "            cx, cy = int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"mm00\"])\n",
    "            centroids.append((cx, cy))\n",
    "    \n",
    "    for bb, centroids in zip(bbs, centroids):\n",
    "        x, y, w, h = bb\n",
    "        cv.rectangle(resized, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv.circle(resized, centroid, 2, (255, 0, 0), -1)\n",
    "        \n",
    "    cv.imshow(\"red object\", resized)\n",
    "    k = cv.waitkey(10) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5094cb48",
   "metadata": {},
   "source": [
    "### Exercise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3da8347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1\n",
    "#sobel\n",
    "img = cv.imread(\"images/pineapple.jfif\", 0)\n",
    "\n",
    "show_img(\"img\", img)\n",
    "\n",
    "sobelx_32f = cv.Sobel(img, cv.CV_32F, 1, 0, ksize = 3)\n",
    "sobely_32f = cv.Sobel(img, cv.CV_32F, 0, 1, ksize = 3)\n",
    "\n",
    "sobel = np.sqrt(sobelx_32f ** 2 + sobely_32f ** 2).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41b896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laplacian\n",
    "laplacian = cv.Laplacian(img, cv.CV_32F, ksize=3)\n",
    "show_img(\"img\", laplacian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a5a88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canny\n",
    "canny = cv.Canny(img, 100, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03e1418",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (14, 12))\n",
    "\n",
    "plt.subplot(321), plt_img(sobel, \"Sobel\")\n",
    "plt.subplot(322), plt_img(laplacian, \"Laplacian\")\n",
    "plt.subplot(323), plt_img(canny, \"Canny\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce3e3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2\n",
    "img = cv.imread(\"images/electronic.jfif\")\n",
    "show_img(\"img\", img)\n",
    "img_copy = img.copy()\n",
    "\n",
    "gray = cv.cvtColor(img_copy, cv.COLOR_RGB2GRAY)\n",
    "\n",
    "threshold = cv.threshold(gray, 183, 255, cv.THRESH_BINARY)[1]\n",
    "\n",
    "contours, _ = cv.findContours(threshold, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# draw contours\n",
    "for c in contours:\n",
    "    x, y, w, h = cv.boundingRect(c)\n",
    "    if w>5 and h>5: \n",
    "        cv.rectangle(img_copy, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "# Display\n",
    "plt.figure(figsize = (5, 2))\n",
    "plt.imshow(cv.cvtColor(img_copy,cv.COLOR_RGB2BGR))\n",
    "plt.title(\"White Object\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbd96ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3\n",
    "img = cv.imread(\"images/clock.jpg\")\n",
    "show_img(\"img\", img)\n",
    "\n",
    "blur = cv.GaussianBlur(img, (3, 3), 0)\n",
    "gray = cv.cvtColor(blur, cv.COLOR_BGR2GRAY)\n",
    "edge = cv.Canny(gray, 50, 150)\n",
    "\n",
    "show_img(\"edge\", edge)\n",
    "\n",
    "# find contour\n",
    "contours, _ = cv.findContours(edge, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "contours = sorted(contours, key=cv.contourArea, reverse = True)[:5]\n",
    "clk = None\n",
    "\n",
    "for c in contours:\n",
    "    peri = cv.arcLength(c, True)\n",
    "    approx = cv.approxPolyDP(c, 0.1*peri, True)\n",
    "    \n",
    "    if len(approx) == 4:\n",
    "        clk = c\n",
    "        break\n",
    "        \n",
    "img_copy = img.copy()\n",
    "cv.drawContours(img_copy, [clk], -1, (0, 255, 0), 2)\n",
    "\n",
    "show_img(\"Clock\", img_copy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
